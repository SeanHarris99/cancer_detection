{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ir502xY6SCYp"
   },
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Written by Sean Harris\n",
    "# \n",
    "# Problem: \n",
    "#   It is not easy to efficiently sample training patches from gigapixel biopsy \n",
    "#   slide. A majority of the slide is non-tissue background, and most of the \n",
    "#   tissue is noncancerous.\n",
    "#\n",
    "# Solution: \n",
    "#   Ahead of training, generate and save a list of indices pointing to slides \n",
    "#   containing tissue (normal and tumorous). Important to not merely iterate \n",
    "#   through entire slide, as it's mostly white background. \n",
    "#\n",
    "#   Instead, the entire slide is rendered in a lower magnification level (6), \n",
    "#   and then large empty regions are filtered out with edge detection. We keep \n",
    "#   regions with lots of edges, as they contain the complex organic tissue.\n",
    "#\n",
    "#   Finally we exhaustively iterate through the remaining regions, filtering\n",
    "#   out slides with little tissue (determined by greyscale intensity), and\n",
    "#   labelling slides containing tumor anotated pixels as tumorous.\n",
    "#\n",
    "# NOTE: \n",
    "#   This file works with slides with pixel tumor annotations in XML form.\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzYvu4t1VHVu"
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "!apt-get install openslide-tools\n",
    "!pip install openslide-python\n",
    " \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openslide import open_slide, __library_version__ as openslide_version\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "import random\n",
    "import copy\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from skimage import feature\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount(\"/content/drive\")\n",
    "slide_root = '/path/to/slide/directory/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mVTPP5aY4RY"
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS\n",
    "\n",
    "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
    "    im = slide.read_region((x,y), level, (width, height))\n",
    "    im = im.convert('RGB') # drop the alpha channel\n",
    "    if as_float:\n",
    "        im = np.asarray(im, dtype=np.float32)\n",
    "    else:\n",
    "        im = np.asarray(im)\n",
    "    assert im.shape == (height, width, 3)\n",
    "    return im\n",
    "\n",
    "def find_tissue_pixels(image, intensity=0.8):\n",
    "    im_gray = rgb2gray(image)\n",
    "    assert im_gray.shape == (image.shape[0], image.shape[1])\n",
    "    indices = np.where(im_gray <= intensity)\n",
    "    return list(zip(indices[0], indices[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXLQ43w0Xc1R"
   },
   "outputs": [],
   "source": [
    "coord_dict = {}\n",
    "input_shape = (299,299,3)\n",
    "     \n",
    "#Scaling factor is how many level 0 pixels there are per \"pixel\" in edges\n",
    "#Patch level is level of magnification of patches that will be trained on\n",
    "\n",
    "for slide_file in os.listdir(slide_root):\n",
    "\n",
    "    slide_path = slide_root + slide_file\n",
    "    slide = open_slide(slide_path)\n",
    "    print(slide_file)\n",
    "\n",
    "    patch_level = 1\n",
    "    thumbnail_level = 6\n",
    "    thumbnail_stride = 100\n",
    "    scaling_factor = int(thumbnail_stride * slide.level_downsamples[thumbnail_level - patch_level]) \n",
    "\n",
    "    coord_path = '/path/to/cords/' + str(patch_level) + '/'\n",
    "    if slide_file[0:-4] + \"_normal.npy\" in os.listdir(coord_path):\n",
    "        print('Skipped ' + slide_file)\n",
    "        continue\n",
    "    \n",
    "    #Step 1: Detect edges in low-res whole-slide\n",
    "    a = read_slide( slide, \n",
    "                    x= 0, \n",
    "                    y= 0, \n",
    "                    level=thumbnail_level, \n",
    "                    width=slide.level_dimensions[thumbnail_level][0], \n",
    "                    height=slide.level_dimensions[thumbnail_level][1])\n",
    "    b = feature.canny(rgb2gray(a))\n",
    "    b = scipy.ndimage.binary_closing(b)\n",
    "    b = scipy.ndimage.binary_dilation(b)\n",
    "    b = scipy.ndimage.binary_fill_holes(b)\n",
    "    b = b.astype(int)\n",
    "\n",
    "    #Step 2: Convolve to generate indicator matrix denoting tissue-rich regions\n",
    "    conv_window = np.full((thumbnail_stride,thumbnail_stride),1)\n",
    "    b = torch.tensor(np.expand_dims(b.astype(int), axis=(0,1)))\n",
    "    conv_window = torch.tensor(np.expand_dims(conv_window, axis=(0,1)))\n",
    "    c = F.conv2d(b, conv_window, stride=thumbnail_stride, padding=0)\n",
    "    c = c.numpy().squeeze()\n",
    "\n",
    "    #Step 3: Get tumor pixels     \n",
    "    root = ET.parse('/path/to/xml/' + slide_file[0:-4] + '.xml').getroot()\n",
    "    tumor_pixels = []                                                                                \n",
    "    for annotation in root[0]:\n",
    "        for coordinate in annotation[0]:\n",
    "            tumor_pixels.append((round(float(coordinate.get('X'))),round(float(coordinate.get('Y')))))\n",
    "\n",
    "    #Step 4: Gather level 1 coords represented by indicator matrix\n",
    "    ratio = .333\n",
    "    edges = np.argwhere(c > (ratio * np.max(c)))\n",
    "    edges = np.fliplr(edges).tolist()                                                   #Remember zeroth axis in numpy is actually y axis in image, so flip axes\n",
    "    normal_coords = []\n",
    "    tumor_coords  = []\n",
    "    for edge in edges:\n",
    "        x_start = edge[0] * scaling_factor\n",
    "        y_start = edge[1] * scaling_factor\n",
    "\n",
    "        x_stop = x_start + scaling_factor\n",
    "        y_stop = y_start + scaling_factor\n",
    "        \n",
    "        for x in range(x_start,x_stop,input_shape[0]):\n",
    "            for y in range(y_start,y_stop,input_shape[1]):\n",
    "\n",
    "                patch = read_slide(slide, x = x, y = y,\n",
    "                                   level  = patch_level,\n",
    "                                   width  = input_shape[0],\n",
    "                                   height = input_shape[1])\n",
    "                tissue_pixels = find_tissue_pixels(patch)\n",
    "                if len(tissue_pixels)/(input_shape[0] * input_shape[1]) < .2:\n",
    "                    continue\n",
    "\n",
    "                for pixel in tumor_pixels:\n",
    "                    if x <= pixel[0] <= (x + input_shape[0]) and y <= pixel[1] <= (y + input_shape[1]):\n",
    "                        tumor_coords.append((x,y))\n",
    "                        break\n",
    "                normal_coords.append((x,y))\n",
    "    np.save(coord_path + slide_file[0:-4] + \"_normal.npy\" ,np.array(normal_coords))\n",
    "    np.save(coord_path + slide_file[0:-4] + \"_tumor.npy\" ,np.array(tumor_coords))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "generate_coords_xml.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
