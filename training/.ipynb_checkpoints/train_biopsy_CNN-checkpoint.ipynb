{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ERoCsWoLmjo"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#Written by Sean Harris\n",
    "#\n",
    "# This notebook contains code to train a CNN on preprocessed gigapixel cancer\n",
    "# biopsy tissue slides.\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NV6skJY1L8dD"
   },
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "!apt-get install openslide-tools\n",
    "!pip install openslide-python\n",
    " \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openslide import open_slide, __library_version__ as openslide_version\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "import random\n",
    "import copy\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from skimage import feature\n",
    "from keras import metrics\n",
    "import time\n",
    "\n",
    " \n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "slide_root='/content/drive/My Drive/ADL_Final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2srMwSLUMNK8"
   },
   "outputs": [],
   "source": [
    "#USEFUL FUNCTIONS\n",
    "\n",
    "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
    "    im = slide.read_region((x,y), level, (width, height))\n",
    "    im = im.convert('RGB') # drop the alpha channel\n",
    "    if as_float:\n",
    "        im = np.asarray(im, dtype=np.float32)\n",
    "    else:\n",
    "        im = np.asarray(im)\n",
    "    assert im.shape == (height, width, 3)\n",
    "    return im\n",
    "\n",
    "def find_tissue_pixels(image, intensity=0.8):\n",
    "    im_gray = rgb2gray(image)\n",
    "    assert im_gray.shape == (image.shape[0], image.shape[1])\n",
    "    indices = np.where(im_gray <= intensity)\n",
    "    return list(zip(indices[0], indices[1]))\n",
    "\n",
    "def aug(image1,image2):\n",
    "    num_rot = random.randint(1,4)\n",
    "    image1 = np.rot90(image1,num_rot)\n",
    "    image2 = np.rot90(image2,num_rot)\n",
    "\n",
    "    if random.random() > .5:\n",
    "        image1 = np.fliplr(image1)\n",
    "        image2 = np.fliplr(image2)\n",
    "    if random.random() > .5:\n",
    "        image1 = np.flipud(image1)\n",
    "        image2 = np.flipud(image2)\n",
    "    return image1,image2\n",
    "\n",
    "def context_coords(j,i,level,slide):\n",
    "    input_shape = (299,299,3)\n",
    "    x_level_0 = int(j * input_shape[0] * slide.level_downsamples[level])\n",
    "    y_level_0 = int(i * input_shape[1] * slide.level_downsamples[level])\n",
    "\n",
    "    x_width_0 = input_shape[0] * slide.level_downsamples[level]\n",
    "    y_width_0 = input_shape[1] * slide.level_downsamples[level]\n",
    "\n",
    "    x_diff = int(np.floor(.5 * x_width_0))\n",
    "    y_diff = int(np.floor(.5 * y_width_0))\n",
    "\n",
    "    x_pos = max(0,x_level_0 - x_diff) \n",
    "    y_pos = max(0,y_level_0 - y_diff)\n",
    "\n",
    "    x_padded_border = slide.level_dimensions[0][0] - input_shape[0] * slide.level_downsamples[level + 1]\n",
    "    y_padded_border = slide.level_dimensions[0][1] - input_shape[1] * slide.level_downsamples[level + 1]\n",
    "\n",
    "    x_pos = int(np.floor(min(x_pos,x_padded_border)))\n",
    "    y_pos = int(np.floor(min(y_pos,y_padded_border)))\n",
    "\n",
    "    return x_pos,y_pos\n",
    "\n",
    "def int_to_path(k):\n",
    "    if k >= 100:\n",
    "        slide_path = slide_root + 'Copy of tumor_' + str(k) + '.tif'\n",
    "        tumor_mask_path = slide_root + 'Copy of tumor_' + str(k) + '_mask.tif'\n",
    "    elif k >= 10:\n",
    "        slide_path = slide_root + 'Copy of tumor_0' + str(k) + '.tif'\n",
    "        tumor_mask_path = slide_root + 'Copy of tumor_0' + str(k) + '_mask.tif'\n",
    "    elif k >= 0:\n",
    "        slide_path = slide_root + 'Copy of tumor_00' + str(k) + '.tif'\n",
    "        tumor_mask_path = slide_root + 'Copy of tumor_00' + str(k) + '_mask.tif'\n",
    "    return slide_path,tumor_mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52x52pZ-MfLr"
   },
   "outputs": [],
   "source": [
    "#GENERATOR\n",
    "#generate_patches_xml for xml labels, generate_patches_tif for tif labels\n",
    "\n",
    "\n",
    "def generate_patches_xml(slide_root='/content/drive/My Drive/ADL_Final/data/',\n",
    "                     patch_root='/content/drive/My Drive/ADL_Final/coords/2/',\n",
    "                     level = 2,\n",
    "                     batch_size=32):\n",
    "    inputs      = []\n",
    "    targets     = []\n",
    "    contexts    = []\n",
    "    batch_count = 0\n",
    "    slides = os.listdir(slide_root)\n",
    "    while True:\n",
    "        for slide_name in slides: \n",
    "            \n",
    "            slide_path = slide_root + slide_name\n",
    "            slide = open_slide(slide_path)\n",
    "\n",
    "            pos_patch_coords_path = patch_root + slide_name[0:-4] + '_tumor.npy'\n",
    "            neg_patch_coords_path = patch_root + slide_name[0:-4] + '_normal.npy'\n",
    "\n",
    "            if not os.path.isfile(pos_patch_coords_path) or not os.path.isfile(neg_patch_coords_path):\n",
    "                continue\n",
    "\n",
    "            pos_patches = np.load(pos_patch_coords_path).tolist()\n",
    "            neg_patches = np.load(neg_patch_coords_path).tolist()\n",
    "            np.random.shuffle(neg_patches)\n",
    "            np.random.shuffle(pos_patches)\n",
    "\n",
    "            input_shape = (299,299,3)\n",
    "\n",
    "            while len(pos_patches) and len(neg_patches):\n",
    "                if random.random() < .5:\n",
    "                    coords = neg_patches.pop()\n",
    "                    j = coords[0]\n",
    "                    i = coords[1]\n",
    "                    label = 0\n",
    "                else:\n",
    "                    coords = pos_patches.pop()\n",
    "                    j = coords[0]\n",
    "                    i = coords[1]\n",
    "                    label = 1\n",
    "\n",
    "                patch = read_slide(slide, \n",
    "                                x= int(j * input_shape[0] * slide.level_downsamples[level]), \n",
    "                                y= int(i * input_shape[1] * slide.level_downsamples[level]), \n",
    "                                level=level, \n",
    "                                width=input_shape[0], \n",
    "                                height=input_shape[1])\n",
    "\n",
    "                x_pos,y_pos = context_coords(j,i,2,slide)\n",
    "                patch_context = read_slide(slide, \n",
    "                                        x= x_pos, \n",
    "                                        y= y_pos, \n",
    "                                        level=level + 1, \n",
    "                                        width=input_shape[0], \n",
    "                                        height=input_shape[1])\n",
    "\n",
    "                patch, patch_context = aug(patch,patch_context)\n",
    "\n",
    "                inputs.append(patch)\n",
    "                contexts.append(patch_context)\n",
    "                targets.append(label)\n",
    "                batch_count += 1\n",
    "                if batch_count >= batch_size: \n",
    "                    yield ([np.array(inputs),np.array(contexts)], np.array(targets))\n",
    "                    inputs = []\n",
    "                    targets = []\n",
    "                    contexts = []\n",
    "                    batch_count = 0\n",
    "\n",
    "def generate_patches_tif(slide_root='/content/drive/My Drive/ADL_Final/',\n",
    "                     level = 2,\n",
    "                     bin_map = bin_maps_lvl2,\n",
    "                     batch_size=32):\n",
    "    inputs      = []\n",
    "    targets     = []\n",
    "    contexts    = []\n",
    "    batch_count = 0\n",
    "    running_avg = 0\n",
    "    while True:\n",
    "        for k in range(150): \n",
    "\n",
    "            slide_path,tumor_mask_path = int_to_path(k)\n",
    "            if k > 90: #Tumor 91 is saved for validation\n",
    "                continue\n",
    "            if not os.path.exists(slide_path) or not os.path.exists(tumor_mask_path):\n",
    "                continue\n",
    "                \n",
    "            slide = open_slide(slide_path)\n",
    "            tumor_mask = open_slide(tumor_mask_path)\n",
    "            input_shape = (299,299,3)\n",
    "\n",
    "            pos_indices_temp,neg_indices_temp = bin_map[slide_path]\n",
    "            pos_indices = copy.deepcopy(pos_indices_temp)\n",
    "            neg_indices = copy.deepcopy(neg_indices_temp)\n",
    "            while len(pos_indices) and len(neg_indices):\n",
    "                if random.random() < .5:\n",
    "                    coords = neg_indices.pop()\n",
    "                    j = coords[0]\n",
    "                    i = coords[1]\n",
    "                    label = 0\n",
    "                else:\n",
    "                    coords = pos_indices.pop()\n",
    "                    j = coords[0]\n",
    "                    i = coords[1]\n",
    "                    label = 1\n",
    "\n",
    "                patch = read_slide(slide, \n",
    "                                x= int(j * input_shape[0] * slide.level_downsamples[level]), \n",
    "                                y= int(i * input_shape[1] * slide.level_downsamples[level]), \n",
    "                                level=level, \n",
    "                                width=input_shape[0], \n",
    "                                height=input_shape[1])\n",
    "\n",
    "                x_pos,y_pos = context_coords(j,i,2,slide)\n",
    "                patch_context = read_slide(slide, \n",
    "                                        x= x_pos, \n",
    "                                        y= y_pos, \n",
    "                                        level=level + 1, \n",
    "                                        width=input_shape[0], \n",
    "                                        height=input_shape[1])\n",
    "\n",
    "                patch, patch_context = aug(patch,patch_context)\n",
    "\n",
    "                inputs.append(patch)\n",
    "                contexts.append(patch_context)\n",
    "                targets.append(label)\n",
    "                batch_count += 1\n",
    "                if batch_count >= batch_size: \n",
    "                    #print(np.mean(targets),len(targets))\n",
    "                    yield ([np.array(inputs),np.array(contexts)], np.array(targets))\n",
    "                    inputs = []\n",
    "                    targets = []\n",
    "                    contexts = []\n",
    "                    batch_count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQ1c6EhARCbs"
   },
   "outputs": [],
   "source": [
    "#BUILD KERAS CNN MODEL\n",
    " \n",
    "input1 = keras.Input(shape=(299, 299, 3))\n",
    "input2 = keras.Input(shape=(299, 299, 3))\n",
    " \n",
    "inception1 = keras.applications.InceptionV3(include_top=False, pooling='max')\n",
    "inception1._name = 'inception1'\n",
    "inception2 = keras.applications.InceptionV3(include_top=False, pooling='max')\n",
    "inception2._name = 'inception2'\n",
    " \n",
    "flat1 = (inception1(preprocess_input(input1)))\n",
    "flat2 = (inception2(preprocess_input(input2))) \n",
    " \n",
    "concat = keras.layers.concatenate([flat1,flat2])\n",
    "dropout = keras.layers.Dropout(0.5)(concat)\n",
    " \n",
    "output = keras.layers.Dense(1, activation='sigmoid')(dropout)\n",
    " \n",
    "model = keras.Model([input1,input2],output)\n",
    " \n",
    "lr = keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate = .002,\n",
    "    decay_steps = 6000,\n",
    "    end_learning_rate = 0.0000001,\n",
    "    power=1.0,\n",
    ")\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=lr,\n",
    "    rho=0.9,\n",
    "    momentum=.1,\n",
    "    #epsilon=1,\n",
    "    \n",
    "\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "             metrics.BinaryAccuracy(),\n",
    "             metrics.AUC(),\n",
    "            \n",
    "    ],\n",
    ")\n",
    "model.summary()\n",
    "#keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykg6bc4VRpky"
   },
   "outputs": [],
   "source": [
    "#TRAIN THE CNN\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='/path/',\n",
    "    save_weights_only=True,\n",
    "    monitor='auc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "batch_size = 32\n",
    "total_tumor_patches = 0\n",
    "for path in os.listdir('/path/to/coords'):\n",
    "    if path[18:-4] == 'tumor':\n",
    "        pos_patches = np.load('path/to/cords' + path).tolist()\n",
    "        total_tumor_patches += len(pos_patches)\n",
    "\n",
    "steps = np.floor((2 * total_tumor_patches)/batch_size)\n",
    "\n",
    "model.fit( \n",
    "    x = generate_patches_tif(batch_size=batch_size, level=2),\n",
    "    epochs = 10, \n",
    "    steps_per_epoch = steps,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    "    shuffle=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "train_biopsy_CNN.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
