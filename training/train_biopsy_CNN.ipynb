{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_biopsy_CNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ERoCsWoLmjo"
      },
      "source": [
        "################################################################################\n",
        "#Written by Sean Harris\n",
        "#\n",
        "# This notebook contains code to train a CNN on preprocessed gigapixel cancer\n",
        "# biopsy tissue slides.\n",
        "################################################################################\n",
        "\n",
        "###############################################################################\n",
        "#NOTES\n",
        "#Looks like google drive doesn't like you rapidly sampling from publicly shared\n",
        "#files. So instead I need to write code block that copies like 100 GB images, \n",
        "#trains on them for maybe 10 epochs, then deletes and loads new ones. Should \n",
        "#take a few hours to load each group. Or just do that manually and train normally.\n",
        "\n",
        "#Also appears that its not learning so preprocessing that creates patch coords\n",
        "#is probably broke. Seems to find ttissue OK so its probably the part that labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV6skJY1L8dD"
      },
      "source": [
        "#IMPORTS\n",
        "\n",
        "!apt-get install openslide-tools\n",
        "!pip install openslide-python\n",
        " \n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from openslide import open_slide, __library_version__ as openslide_version\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gdown\n",
        "from zipfile import ZipFile\n",
        "import math\n",
        "import random\n",
        "import sklearn\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "import random\n",
        "import copy\n",
        "import scipy\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from skimage import feature\n",
        "from keras import metrics\n",
        "import time\n",
        "\n",
        " \n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "slide_root='/content/drive/My Drive/ADL_Final/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2srMwSLUMNK8"
      },
      "source": [
        "#USEFUL FUNCTIONS\n",
        "\n",
        "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
        "    im = slide.read_region((x,y), level, (width, height))\n",
        "    im = im.convert('RGB') # drop the alpha channel\n",
        "    if as_float:\n",
        "        im = np.asarray(im, dtype=np.float32)\n",
        "    else:\n",
        "        im = np.asarray(im)\n",
        "    assert im.shape == (height, width, 3)\n",
        "    return im\n",
        "\n",
        "def find_tissue_pixels(image, intensity=0.8):\n",
        "    im_gray = rgb2gray(image)\n",
        "    assert im_gray.shape == (image.shape[0], image.shape[1])\n",
        "    indices = np.where(im_gray <= intensity)\n",
        "    return list(zip(indices[0], indices[1]))\n",
        "\n",
        "def aug(image1,image2):\n",
        "    num_rot = random.randint(1,4)\n",
        "    image1 = np.rot90(image1,num_rot)\n",
        "    image2 = np.rot90(image2,num_rot)\n",
        "\n",
        "    if random.random() > .5:\n",
        "        image1 = np.fliplr(image1)\n",
        "        image2 = np.fliplr(image2)\n",
        "    if random.random() > .5:\n",
        "        image1 = np.flipud(image1)\n",
        "        image2 = np.flipud(image2)\n",
        "    return image1,image2\n",
        "\n",
        "def context_coords(j,i,level,slide):\n",
        "    input_shape = (299,299,3)\n",
        "    x_level_0 = int(j * input_shape[0] * slide.level_downsamples[level])\n",
        "    y_level_0 = int(i * input_shape[1] * slide.level_downsamples[level])\n",
        "\n",
        "    x_width_0 = input_shape[0] * slide.level_downsamples[level]\n",
        "    y_width_0 = input_shape[1] * slide.level_downsamples[level]\n",
        "\n",
        "    x_diff = int(np.floor(.5 * x_width_0))\n",
        "    y_diff = int(np.floor(.5 * y_width_0))\n",
        "\n",
        "    x_pos = max(0,x_level_0 - x_diff) \n",
        "    y_pos = max(0,y_level_0 - y_diff)\n",
        "\n",
        "    x_padded_border = slide.level_dimensions[0][0] - input_shape[0] * slide.level_downsamples[level + 1]\n",
        "    y_padded_border = slide.level_dimensions[0][1] - input_shape[1] * slide.level_downsamples[level + 1]\n",
        "\n",
        "    x_pos = int(np.floor(min(x_pos,x_padded_border)))\n",
        "    y_pos = int(np.floor(min(y_pos,y_padded_border)))\n",
        "\n",
        "    return x_pos,y_pos\n",
        "\n",
        "def int_to_path(k):\n",
        "    if k >= 100:\n",
        "        slide_path = slide_root + 'Copy of tumor_' + str(k) + '.tif'\n",
        "        tumor_mask_path = slide_root + 'Copy of tumor_' + str(k) + '_mask.tif'\n",
        "    elif k >= 10:\n",
        "        slide_path = slide_root + 'Copy of tumor_0' + str(k) + '.tif'\n",
        "        tumor_mask_path = slide_root + 'Copy of tumor_0' + str(k) + '_mask.tif'\n",
        "    elif k >= 0:\n",
        "        slide_path = slide_root + 'Copy of tumor_00' + str(k) + '.tif'\n",
        "        tumor_mask_path = slide_root + 'Copy of tumor_00' + str(k) + '_mask.tif'\n",
        "    return slide_path,tumor_mask_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52x52pZ-MfLr"
      },
      "source": [
        "#GENERATOR\n",
        "\n",
        "def generate_patches(slide_root='/content/drive/My Drive/ADL_Final/data/',\n",
        "                     patch_root='/content/drive/My Drive/ADL_Final/coords/2/',\n",
        "                     level = 2,\n",
        "                     batch_size=32):\n",
        "    inputs      = []\n",
        "    targets     = []\n",
        "    contexts    = []\n",
        "    batch_count = 0\n",
        "    slides = os.listdir(slide_root)\n",
        "    while True:\n",
        "        for slide_name in slides: \n",
        "            \n",
        "            slide_path = slide_root + slide_name\n",
        "            slide = open_slide(slide_path)\n",
        "\n",
        "            pos_patch_coords_path = patch_root + slide_name[0:-4] + '_tumor.npy'\n",
        "            neg_patch_coords_path = patch_root + slide_name[0:-4] + '_normal.npy'\n",
        "\n",
        "            if not os.path.isfile(pos_patch_coords_path) or not os.path.isfile(neg_patch_coords_path):\n",
        "                continue\n",
        "\n",
        "            pos_patches = np.load(pos_patch_coords_path).tolist()\n",
        "            neg_patches = np.load(neg_patch_coords_path).tolist()\n",
        "            np.random.shuffle(neg_patches)\n",
        "            np.random.shuffle(pos_patches)\n",
        "\n",
        "            input_shape = (299,299,3)\n",
        "\n",
        "            while len(pos_patches) and len(neg_patches):\n",
        "                if random.random() < .5:\n",
        "                    coords = neg_patches.pop()\n",
        "                    j = coords[0]\n",
        "                    i = coords[1]\n",
        "                    label = 0\n",
        "                else:\n",
        "                    coords = pos_patches.pop()\n",
        "                    j = coords[0]\n",
        "                    i = coords[1]\n",
        "                    label = 1\n",
        "\n",
        "                patch = read_slide(slide, \n",
        "                                x= int(j * input_shape[0] * slide.level_downsamples[level]), \n",
        "                                y= int(i * input_shape[1] * slide.level_downsamples[level]), \n",
        "                                level=level, \n",
        "                                width=input_shape[0], \n",
        "                                height=input_shape[1])\n",
        "\n",
        "                x_pos,y_pos = context_coords(j,i,2,slide)\n",
        "                patch_context = read_slide(slide, \n",
        "                                        x= x_pos, \n",
        "                                        y= y_pos, \n",
        "                                        level=level + 1, \n",
        "                                        width=input_shape[0], \n",
        "                                        height=input_shape[1])\n",
        "\n",
        "                patch, patch_context = aug(patch,patch_context)\n",
        "\n",
        "                inputs.append(patch)\n",
        "                contexts.append(patch_context)\n",
        "                targets.append(label)\n",
        "                batch_count += 1\n",
        "                if batch_count >= batch_size: \n",
        "                    yield ([np.array(inputs),np.array(contexts)], np.array(targets))\n",
        "                    inputs = []\n",
        "                    targets = []\n",
        "                    contexts = []\n",
        "                    batch_count = 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ1c6EhARCbs"
      },
      "source": [
        "#BUILD KERAS CNN MODEL\n",
        " \n",
        "input1 = keras.Input(shape=(299, 299, 3))\n",
        "input2 = keras.Input(shape=(299, 299, 3))\n",
        " \n",
        "inception1 = keras.applications.InceptionV3(include_top=False, pooling='max')\n",
        "inception1._name = 'inception1'\n",
        "inception2 = keras.applications.InceptionV3(include_top=False, pooling='max')\n",
        "inception2._name = 'inception2'\n",
        " \n",
        "flat1 = (inception1(preprocess_input(input1)))\n",
        "flat2 = (inception2(preprocess_input(input2))) \n",
        " \n",
        "concat = keras.layers.concatenate([flat1,flat2])\n",
        "dropout = keras.layers.Dropout(0.5)(concat)\n",
        " \n",
        "output = keras.layers.Dense(1, activation='sigmoid')(dropout)\n",
        " \n",
        "model = keras.Model([input1,input2],output)\n",
        " \n",
        "lr = keras.optimizers.schedules.PolynomialDecay(\n",
        "    initial_learning_rate = .002,\n",
        "    decay_steps = 6000,\n",
        "    end_learning_rate = 0.0000001,\n",
        "    power=1.0,\n",
        ")\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=lr,\n",
        "    rho=0.9,\n",
        "    momentum=.1,\n",
        "    #epsilon=1,\n",
        "    \n",
        "\n",
        ")\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\n",
        "             metrics.BinaryAccuracy(),\n",
        "             metrics.AUC(),\n",
        "            \n",
        "    ],\n",
        ")\n",
        "model.summary()\n",
        "#keras.utils.plot_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRivNkG-yco4"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/ADL_Final/checkpoint7/weights8.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykg6bc4VRpky"
      },
      "source": [
        "#TRAIN THE CNN\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/My Drive/ADL_Final/checkpoint7/weights9.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='auc',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "batch_size = 32\n",
        "total_tumor_patches = 0\n",
        "for path in os.listdir('/content/drive/My Drive/ADL_Final/coords/2/'):\n",
        "    if path[18:-4] == 'tumor':\n",
        "        pos_patches = np.load('/content/drive/My Drive/ADL_Final/coords/2/' + path).tolist()\n",
        "        total_tumor_patches += len(pos_patches)\n",
        "\n",
        "steps = np.floor((2 * total_tumor_patches)/batch_size)\n",
        "\n",
        "model.fit( \n",
        "    x = generate_patches(batch_size=batch_size, level=2),\n",
        "    epochs = 10, \n",
        "    steps_per_epoch = steps,\n",
        "    callbacks=[model_checkpoint_callback],\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of-kLqH40_8M"
      },
      "source": [
        "a = open_slide('/content/drive/My Drive/ADL_Final/Copy of tumor_091.tif')\n",
        "plt.imshow(a.get_thumbnail((300,300)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}